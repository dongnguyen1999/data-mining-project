# -*- coding: utf-8 -*-
"""Cluster handwritten letter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SprGFb4cT_gdBme-XJ2MeKWwMJXF1j6r
"""

#Output were saved at: https://drive.google.com/drive/folders/1i41u5jyd_IplYH1-WjeSfjXBRtGxy1Ch?usp=sharing

#preprocessing
import cv2
import matplotlib.pylab as plt
import pandas as pd
import numpy as np
from glob import glob
import os


def read_imgs():
  print('Start to read raw images')
  imgs_path = '/content/drive/My Drive/Dataset/Vietnamese-handwritten-letters/sample/images/raw'
  imgs_glob = glob(os.path.join(imgs_path, "*.jpg"))
  images = []
  filenames = []
  for i in range(len(imgs_glob)):
    img_path = imgs_glob[i];
    filename = os.path.basename(img_path)
    print('Loading image ' + filename + '..., Total processing ' + str(i*100.0/len(imgs_glob)) + '%')
    filenames.append(filename)
    images.append(cv2.imread(img_path))
  print('Read raw images successfully')
  return filenames, images

def write_imgs(filenames, images):
  print('Start to save preprocessed images')
  save_imgs_path = '/content/drive/My Drive/Dataset/Vietnamese-handwritten-letters/sample/images/preprocessed'
  for i in range(len(images)):
    filename = filenames[i]
    image = images[i]
    save_path = os.path.join(save_imgs_path, filename)
    cv2.imwrite(save_path, image)
  print('Write images successfully')

filenames, images = read_imgs()

images = np.array(images)

# Convert to gray image
gray_imgs = list(map( lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ,images))

# Convert to black and white image
black_white_imgs = list(map(lambda img: cv2.threshold(img, 180, 255, cv2.THRESH_BINARY)[1], gray_imgs))

# Resize from (128,128) to (32,32)
_32x32_imgs = np.array(list(map(lambda img: cv2.resize(img, (32,32), interpolation=cv2.INTER_CUBIC), black_white_imgs)))

#Normalization
_32x32_imgs = _32x32_imgs//255

#Remove redundant pixel from 4 edges of image
def fillWhiteToEdges(img, edgesWidth, imgSize):
  for i in range(edgesWidth):
    for j in range(imgSize-2*i):
      img[i][j] = 1
      img[j][i] = 1
      img[imgSize-i-1][j] = 1
      img[j][imgSize-i-1] = 1
  return img
      

#Remove redundant border from images
_32x32_imgs = np.array(list(map(lambda img: fillWhiteToEdges(img, 1, 32), _32x32_imgs)))

#Reshape images from (32,32) to (1024,)
_32x32_imgs = _32x32_imgs.reshape(len(_32x32_imgs),-1)

#Save as csv training data
np.savetxt('/content/drive/My Drive/Dataset/Vietnamese-handwritten-letters/sample/preprocessed_data.csv', _32x32_imgs, delimiter=';')


# plt.gray() # B/W Images
# plt.figure(figsize = (10,9)) # Adjusting figure size
# # Displaying a grid of 3x3 images
# for i in range(len(_32x32_imgs)):
#  plt.subplot(3,3,i+1)
#  plt.imshow(_32x32_imgs[i])

import pandas as pd
# Show elbow diagram
# data = pd.read_csv('/content/drive/My Drive/Dataset/Vietnamese-handwritten-letters/sample/preprocessed_data.csv', delimiter=';')

# from sklearn.cluster import MiniBatchKMeans
# nbs_clusters = range(1, 25);
# clusters = []
# for i in nbs_clusters:
#   print('Clustering with %d clusters...' % (i))
#   km = MiniBatchKMeans(n_clusters=i).fit(data)
#   clusters.append(km.inertia_)

# import matplotlib.pyplot as plt
# import seaborn as sns
# fig, ax = plt.subplots(figsize=(12, 8))
# sns.lineplot(x=list(nbs_clusters), y=clusters, ax=ax)
# ax.set_title('Đồ thị Elbow')
# ax.set_xlabel('Số lượng nhóm')
# ax.set_ylabel('Giá trị Inertia')
# plt.show()
# plt.cla()


#Clustering
possible_k = [4, 9, 11, 13, 15, 17, 18]

from sklearn.cluster import KMeans
def cluster(image_source, training_data, k):
  print('Started training kmean model with k = ' + str(k))
  nb_clusters = k
  kmeans = KMeans(n_clusters = nb_clusters)
  y_mean = kmeans.fit_predict(training_data)
  print('Train model successfully')

  print('Started save clusters')
  parent_dir = "/content/drive/My Drive/Dataset/Vietnamese-handwritten-letters/sample/images/clustered"+str(k)
  os.mkdir(parent_dir)
  for i in range(nb_clusters):
    directory = str(i)
    save_dir = os.path.join(parent_dir, directory)
    os.mkdir(save_dir)
    cl = image_source[y_mean == i]
    for index, row in cl.iterrows():
      filename = row['filename']
      image = row['image']
      cv2.imwrite(os.path.join(save_dir, filename), image)
    print('Saved ' + str(i+1) +' clusters')


data = pd.read_csv('/content/drive/My Drive/Dataset/Vietnamese-handwritten-letters/sample/preprocessed_data.csv', delimiter=';', header=None)
filenames, images = read_imgs()
source = pd.concat([pd.Series(filenames), pd.Series(images)], axis=1, keys=['filename', 'image'])

for k in possible_k:
  cluster(source, data, k)
